{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 15 11:41:48 2017\n",
    "\n",
    "@author: WangJin_XuHan\n",
    "\"\"\"\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import datestr2num\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare the data and then read them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_faces_path = 'D:/Desktop/InfoProject/face_jp/my_final'\n",
    "other_faces_path = 'D:/Desktop/InfoProject/face_jp/noise_final'\n",
    "size = 64\n",
    "\n",
    "imgs = []\n",
    "# labs = []\n",
    "pathes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here make the input image as square\n",
    "def getPaddingSize(img):\n",
    "    h, w, _ = img.shape\n",
    "    top, bottom, left, right = (0,0,0,0)\n",
    "    longest = max(h, w)\n",
    "\n",
    "    if w < longest:\n",
    "        tmp = longest - w\n",
    "        # // is Floor Division; 9//2 = 4\n",
    "        left = tmp // 2\n",
    "        right = tmp - left\n",
    "    elif h < longest:\n",
    "        tmp = longest - h\n",
    "        top = tmp // 2\n",
    "        bottom = tmp - top\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    return top, bottom, left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def readData(path, h=size, w=size):\n",
    "def readData(path):\n",
    "    for filename in os.listdir(path):    #get names of files or folders\n",
    "        if filename.endswith('.jpg'):\n",
    "            filename = path + '/' + filename\n",
    "            \n",
    "            #read image with cv2\n",
    "            img = cv2.imread(filename)               \n",
    "            #the four means space to fill on which direction to make image square\n",
    "            top,bottom,left,right = getPaddingSize(img)        \n",
    "            # enlare the picture, filled the edges with zeros\n",
    "            img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0,0,0])            \n",
    "            \n",
    "            #we can resize here, but no not need to, because our data has been resized\n",
    "          \n",
    "            #create matrix array\n",
    "            imgs.append(img)            \n",
    "            #useful storage for the following step creating lables \n",
    "            pathes.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed! train size:16100, test size:6900\n"
     ]
    }
   ],
   "source": [
    "#read data and split the data set\n",
    "readData(my_faces_path)\n",
    "readData(other_faces_path)\n",
    "\n",
    "# append matrix array (from picture) in to array; not that necessary but good \n",
    "imgs = np.array(imgs)\n",
    "# creat lable array for supervised learning; #one line ifelse makes python looks like pseudo code\n",
    "labs = np.array([[0,1] if lab == my_faces_path else [1,0] for lab in pathes])   \n",
    "\n",
    "# split the training data set and test dataset; test_ratio is ration of test data set\n",
    "test_ratio = 0.3\n",
    "train_x,test_x,train_y,test_y = train_test_split(imgs, labs, test_size=test_ratio, random_state=random.randint(0,100))\n",
    "\n",
    "# number of pics,hight,width,3 means color picture\n",
    "train_x = train_x.reshape(train_x.shape[0], size, size, 3)\n",
    "test_x = test_x.reshape(test_x.shape[0], size, size, 3)\n",
    "\n",
    "#Normalization\n",
    "train_x = train_x.astype('float32')/255.0\n",
    "test_x = test_x.astype('float32')/255.0\n",
    "\n",
    "print('Split completed! train size:%s, test size:%s' % (len(train_x), len(test_x)))\n",
    "\n",
    "#batch is to avoid the ram jam\n",
    "batch_size_read = 200\n",
    "#get interger using ceiling\n",
    "num_batch_train = math.ceil(len(train_x) / batch_size_read)\n",
    "num_batch_test = math.ceil(len(test_x) / batch_size_read) \n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, size, size, 3])\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "\n",
    "#drop_out hence avoid overfitting\n",
    "keep_prob_5 = tf.placeholder(tf.float32)\n",
    "keep_prob_75 = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build the CNN network with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#paprameter for the different layers\n",
    "def weightVariable(shape):\n",
    "    init = tf.random_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def biasVariable(shape):\n",
    "    init = tf.random_normal(shape)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "def maxPool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def dropout(x, keep):\n",
    "    return tf.nn.dropout(x, keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnnLayer():\n",
    "\n",
    "    #first layer\n",
    "    W1 = weightVariable([3,3,3,32]) # filter(3,3)， input channel(3)， output channel(32)\n",
    "    b1 = biasVariable([32])\n",
    "    #concoluntion layer\n",
    "    conv1 = tf.nn.relu(conv2d(x, W1) + b1)\n",
    "    #pooling layer\n",
    "    pool1 = maxPool(conv1)\n",
    "    # dropout is to avoid fitting\n",
    "    drop1 = dropout(pool1, keep_prob_5)\n",
    "\n",
    "    # second layer\n",
    "    W2 = weightVariable([3,3,32,64])\n",
    "    b2 = biasVariable([64])\n",
    "    conv2 = tf.nn.relu(conv2d(drop1, W2) + b2)\n",
    "    pool2 = maxPool(conv2)\n",
    "    drop2 = dropout(pool2, keep_prob_5)\n",
    "\n",
    "    # third layer\n",
    "    W3 = weightVariable([3,3,64,64])\n",
    "    b3 = biasVariable([64])\n",
    "    conv3 = tf.nn.relu(conv2d(drop2, W3) + b3)\n",
    "    pool3 = maxPool(conv3)\n",
    "    drop3 = dropout(pool3, keep_prob_5)\n",
    "\n",
    "    # full connection layer1\n",
    "    Wf = weightVariable([8*16*32, 512])\n",
    "    bf = biasVariable([512])\n",
    "    drop3_flat = tf.reshape(drop3, [-1, 8*16*32])\n",
    "    dense = tf.nn.relu(tf.matmul(drop3_flat, Wf) + bf)\n",
    "    dropf = dropout(dense, keep_prob_75)\n",
    "\n",
    "    # output layer\n",
    "    Wout = weightVariable([512,2])\n",
    "    #bout = weightVariable([2])\n",
    "    bout = biasVariable([2])\n",
    "    #out = tf.matmul(dropf, Wout) + bout\n",
    "    out = tf.add(tf.matmul(dropf, Wout), bout)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnnTrain(epoch_num=20, batch_size=200):\n",
    "    #call cnnLayer to build architecture\n",
    "    out = cnnLayer()\n",
    "    \n",
    "    #Here we use cross entropy as loss fuction\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y_))\n",
    "    \n",
    "    #train the model using Ada#m Optimizer\n",
    "    train_step = tf.train.AdamOptimizer(0.005).minimize(cross_entropy)\n",
    "    \n",
    "    #prepare the accuracy evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #this is to help the calculate the accuracy\n",
    "    acc_sum = 0\n",
    "    \n",
    "    #prepare the visualization using matplot line plot   \n",
    "    #use pandas dataframe to store the (#epoh,accuracy)\n",
    "    accu_df = pd.DataFrame(np.random.randint(low=0, high=1, size=(epoch_num, 1)),columns=['accuracy']) \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            for i in range(num_batch_train):\n",
    "                batch_x = train_x[i*batch_size : (i+1)*batch_size]\n",
    "                batch_y = train_y[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "                # start train! exciting!\n",
    "                _,loss = sess.run([train_step, cross_entropy],\n",
    "                                          feed_dict={x:batch_x,y_:batch_y, keep_prob_5:0.5,keep_prob_75:0.75})\n",
    "            print('Awesome! Completed No. %d epoch of training!'%(epoch))            \n",
    "\n",
    "        \n",
    "        #test model part\n",
    "            for j in range(num_batch_test):\n",
    "                batch_test_x = test_x[j*batch_size : (j+1)*batch_size]\n",
    "                batch_tset_y = test_y[j*batch_size : (j+1)*batch_size]\n",
    "\n",
    "                acc = accuracy.eval({x:batch_test_x, y_:batch_tset_y, keep_prob_5:1.0, keep_prob_75:1.0})\n",
    "\n",
    "                #print(\"%d batch's accuracy: %f\"%((j+1),acc))\n",
    "\n",
    "            #calculate the mean\n",
    "            acc_sum += acc\n",
    "            acc_mean = acc_sum/(epoch+1)\n",
    "            print('So far accuracy: %f'%acc_mean) \n",
    "            \n",
    "            #store the accuracy into the dataframe(table)\n",
    "            accu_df.loc[epoch] = acc_mean\n",
    "\n",
    "    print('Finish! You are genius!')\n",
    " \n",
    "    return accu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome! Completed No. 0 epoch of training!\n",
      "So far accuracy: 0.900000\n",
      "Awesome! Completed No. 1 epoch of training!\n",
      "So far accuracy: 0.910000\n",
      "Awesome! Completed No. 2 epoch of training!\n",
      "So far accuracy: 0.930000\n",
      "Awesome! Completed No. 3 epoch of training!\n",
      "So far accuracy: 0.942500\n",
      "Awesome! Completed No. 4 epoch of training!\n",
      "So far accuracy: 0.952000\n",
      "Awesome! Completed No. 5 epoch of training!\n",
      "So far accuracy: 0.958333\n",
      "Awesome! Completed No. 6 epoch of training!\n",
      "So far accuracy: 0.962857\n",
      "Awesome! Completed No. 7 epoch of training!\n",
      "So far accuracy: 0.963750\n",
      "Awesome! Completed No. 8 epoch of training!\n",
      "So far accuracy: 0.964444\n",
      "Awesome! Completed No. 9 epoch of training!\n",
      "So far accuracy: 0.966000\n",
      "Awesome! Completed No. 10 epoch of training!\n",
      "So far accuracy: 0.968182\n",
      "Awesome! Completed No. 11 epoch of training!\n",
      "So far accuracy: 0.970000\n",
      "Awesome! Completed No. 12 epoch of training!\n",
      "So far accuracy: 0.970769\n",
      "Awesome! Completed No. 13 epoch of training!\n",
      "So far accuracy: 0.972857\n",
      "Awesome! Completed No. 14 epoch of training!\n",
      "So far accuracy: 0.974000\n",
      "Awesome! Completed No. 15 epoch of training!\n",
      "So far accuracy: 0.975625\n",
      "Awesome! Completed No. 16 epoch of training!\n",
      "So far accuracy: 0.977059\n",
      "Awesome! Completed No. 17 epoch of training!\n",
      "So far accuracy: 0.977778\n",
      "Awesome! Completed No. 18 epoch of training!\n",
      "So far accuracy: 0.978421\n",
      "Awesome! Completed No. 19 epoch of training!\n",
      "So far accuracy: 0.978000\n",
      "Finish! You are genius!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.962857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.963750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.964444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.968182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.970769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.972857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.975625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.977059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.978421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.978000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy\n",
       "0   0.900000\n",
       "1   0.910000\n",
       "2   0.930000\n",
       "3   0.942500\n",
       "4   0.952000\n",
       "5   0.958333\n",
       "6   0.962857\n",
       "7   0.963750\n",
       "8   0.964444\n",
       "9   0.966000\n",
       "10  0.968182\n",
       "11  0.970000\n",
       "12  0.970769\n",
       "13  0.972857\n",
       "14  0.974000\n",
       "15  0.975625\n",
       "16  0.977059\n",
       "17  0.977778\n",
       "18  0.978421\n",
       "19  0.978000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#main function\n",
    "epoch_num=20\n",
    "batch_size=200\n",
    "\n",
    "#call main function\n",
    "accu_epoch = cnnTrain(epoch_num, batch_size)\n",
    "accu_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Visualize the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store the result\n",
    "accu_epoch.to_csv('final_test.csv',index=False,header=True)\n",
    "\n",
    "#read accuracy data and visualize it\n",
    "final_test = pd.read_csv('final_test.csv')\n",
    "\n",
    "#combine the accuracy tables  \n",
    "accu_epoch =pd.concat([final_test], axis=1)\n",
    "print(accu_epoch)\n",
    "\n",
    "#plot the combines table\n",
    "accu_epoch.plot( kind='line',title='accuracy along with epoches(batch size 200)',grid=True,legend=True,figsize=(12,8))\n",
    "\n",
    "plt.savefig('accuracy_final.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
